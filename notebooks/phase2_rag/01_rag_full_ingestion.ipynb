{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUIDAR IA - Ingesta Completa del Sistema RAG\n",
    "\n",
    "**Objetivo:** Procesar la colección completa de documentos científicos para crear la base de conocimiento del sistema RAG.\n",
    "\n",
    "**Fase:** 2 - RAG Development (Producción)\n",
    "\n",
    "**Documentos a procesar:**\n",
    "- Enfoques Clínicos y Sistemas de Salud (10 documentos)\n",
    "- Fundamentos Éticos y Gobernanza de Datos (10 documentos)\n",
    "- Perspectivas Salud Pública y Comunitaria (10 documentos)\n",
    "\n",
    "**Total:** 30 documentos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta del proyecto: /Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia\n",
      "API Key configurada: Sí\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar variables de entorno\n",
    "project_root = Path.cwd().parent.parent\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "print(f\"Ruta del proyecto: {project_root}\")\n",
    "print(f\"API Key configurada: {'Sí' if os.getenv('OPENAI_API_KEY') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import tiktoken\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descubrimiento de Documentos\n",
    "\n",
    "Escaneo automático de todas las carpetas para identificar los PDFs disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaneando carpetas de documentos...\n",
      "\n",
      "Enfoques Clínicos y Sistemas de Salud:\n",
      "  Documentos encontrados: 10\n",
      "    - mhGAP Intervention Guide.pdf\n",
      "    - Suicide and suicide risk.pdf\n",
      "    - Internacional Handbook of Suicide Prevention.pdf.pdf\n",
      "    - Screening_for_Suicide_Risk_in_.pdf\n",
      "    - Crisis Suicida 2.pdf\n",
      "    - Clinical Pathway for Suicide Risk Screening in Adult Primary Care Settings Special Recommendations.pdf\n",
      "    - LIVE LIFE.pdf\n",
      "    - Suicidal Ideation and Suicide Attempts After Direct or Indirect Psychotherapy.pdf\n",
      "    - Predicting Suicide Attempts and Suicide Deaths Following Outpatient Visits Using Electronic Health Records.pdf\n",
      "    - Risk Factors for Suicidal Thoughts and Behaviors.pdf\n",
      "\n",
      "Fundamentos Éticos y Gobernanza de Datos:\n",
      "  Documentos encontrados: 10\n",
      "    - A comprehensive review of data analytics in healthcare management Leveraging big data for decision making.pdf\n",
      "    - Empirical evaluation of internal validation methods for prediction in large-scale clinical data with rare event outcomes a case study in suicide risk prediction.pdf\n",
      "    - Who Owns the Data? Open Data for Healthcare.pdf\n",
      "    - A Stakeholder-Informed Ethical Framework to Guide Implementation of Suicide Risk Prediction Models Derived from Electronic Health Records.pdf\n",
      "    - Big data governance of personal health information and challenges to contextual integrity.pdf\n",
      "    - Data Science in Healthcare Benefits Challenges and Opportunities.pdf\n",
      "    - The Ethics of Big Data.pdf\n",
      "    - Values challenges and future directions of big data analytics in healthcare A systematic review.pdf\n",
      "    - ETHICS AND GOVERNANCE OF ARTIFICIAL INTELLIGENCE FOR HEALTH.pdf\n",
      "    - Preventing suicide A global imperative.pdf\n",
      "\n",
      "Perspectivas Salud Pública y Comunitaria:\n",
      "  Documentos encontrados: 9\n",
      "    - A Public Health, Whole of Government Approach to National Suicide Prevention Strategies.pdf\n",
      "    - Suicide Postvention Service Models and Guidelines.pdf\n",
      "    - The social determinants of suicide.pdf\n",
      "    - Characteristics of surveillance systems for suicide and self harm A scoping review.pdf\n",
      "    - Guia comunicacional prevencion del suicidio en medios.pdf\n",
      "    - Real-Time Suicide Surveillance  Comparison of International Surveillance Systems and Recommended Best Practice.pdf\n",
      "    - Gatekeeper training for suicidal behaviors.pdf\n",
      "    - Effectiveness of suicide prevention interventions A systematic review and meta analysis.pdf\n",
      "    - Preventing-suicide--a-public-health-approach-to-a-.pdf\n",
      "\n",
      "\n",
      "Total de documentos a procesar: 29\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de las carpetas de documentos\n",
    "pdf_base_path = project_root / \"data/pdf_papers\"\n",
    "\n",
    "categories = {\n",
    "    \"clinical\": \"Enfoques Clínicos y Sistemas de Salud\",\n",
    "    \"ethics\": \"Fundamentos Éticos y Gobernanza de Datos\",\n",
    "    \"public_health\": \"Perspectivas Salud Pública y Comunitaria\"\n",
    "}\n",
    "\n",
    "# Descubrir todos los PDFs\n",
    "all_pdfs = {}\n",
    "total_files = 0\n",
    "\n",
    "print(\"Escaneando carpetas de documentos...\\n\")\n",
    "\n",
    "for category_key, category_name in categories.items():\n",
    "    folder_path = pdf_base_path / category_name\n",
    "    \n",
    "    if folder_path.exists():\n",
    "        pdf_files = list(folder_path.glob(\"*.pdf\"))\n",
    "        all_pdfs[category_key] = {\n",
    "            \"name\": category_name,\n",
    "            \"path\": folder_path,\n",
    "            \"files\": pdf_files\n",
    "        }\n",
    "        total_files += len(pdf_files)\n",
    "        \n",
    "        print(f\"{category_name}:\")\n",
    "        print(f\"  Documentos encontrados: {len(pdf_files)}\")\n",
    "        for pdf in pdf_files:\n",
    "            print(f\"    - {pdf.name}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Carpeta no encontrada: {folder_path}\")\n",
    "\n",
    "print(f\"\\nTotal de documentos a procesar: {total_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracción de Texto\n",
    "\n",
    "Proceso de extracción de texto de todos los PDFs con manejo de errores y metadata enriquecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de extracción definida\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path, category_key, category_name):\n",
    "    \"\"\"\n",
    "    Extrae texto de un PDF con metadata enriquecida.\n",
    "    \n",
    "    Retorna:\n",
    "    - Tupla (texto, metadata) o (None, None) si hay error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        \n",
    "        # Extraer texto de todas las páginas\n",
    "        full_text = \"\"\n",
    "        for page_num, page in enumerate(reader.pages, start=1):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += f\"\\n{text}\"\n",
    "        \n",
    "        # Crear metadata\n",
    "        metadata = {\n",
    "            \"filename\": pdf_path.name,\n",
    "            \"category_key\": category_key,\n",
    "            \"category_name\": category_name,\n",
    "            \"num_pages\": len(reader.pages),\n",
    "            \"text_length\": len(full_text),\n",
    "            \"file_path\": str(pdf_path)\n",
    "        }\n",
    "        \n",
    "        return full_text.strip(), metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error al procesar {pdf_path.name}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"Función de extracción definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando extracción de texto...\n",
      "\n",
      "Procesando: Enfoques Clínicos y Sistemas de Salud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 245 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "Ignoring wrong pointing object 250 0 (offset 0)\n",
      "Ignoring wrong pointing object 253 0 (offset 0)\n",
      "Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "Ignoring wrong pointing object 259 0 (offset 0)\n",
      "Ignoring wrong pointing object 277 0 (offset 0)\n",
      "Ignoring wrong pointing object 283 0 (offset 0)\n",
      "Ignoring wrong pointing object 5866 0 (offset 0)\n",
      "Ignoring wrong pointing object 5868 0 (offset 0)\n",
      "Ignoring wrong pointing object 5870 0 (offset 0)\n",
      "Ignoring wrong pointing object 11461 0 (offset 0)\n",
      "Ignoring wrong pointing object 11463 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OK: mhGAP Intervention Guide.pdf (174 páginas)\n",
      "  OK: Suicide and suicide risk.pdf (51 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OK: Internacional Handbook of Suicide Prevention.pdf.pdf (670 páginas)\n",
      "  OK: Screening_for_Suicide_Risk_in_.pdf (14 páginas)\n",
      "  OK: Crisis Suicida 2.pdf (345 páginas)\n",
      "  OK: Clinical Pathway for Suicide Risk Screening in Adult Primary Care Settings Special Recommendations.pdf (14 páginas)\n",
      "  OK: LIVE LIFE.pdf (142 páginas)\n",
      "  OK: Suicidal Ideation and Suicide Attempts After Direct or Indirect Psychotherapy.pdf (8 páginas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 168 0 (offset 0)\n",
      "Ignoring wrong pointing object 215 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OK: Predicting Suicide Attempts and Suicide Deaths Following Outpatient Visits Using Electronic Health Records.pdf (10 páginas)\n",
      "  OK: Risk Factors for Suicidal Thoughts and Behaviors.pdf (46 páginas)\n",
      "\n",
      "Procesando: Fundamentos Éticos y Gobernanza de Datos\n",
      "  OK: A comprehensive review of data analytics in healthcare management Leveraging big data for decision making.pdf (12 páginas)\n",
      "  OK: Empirical evaluation of internal validation methods for prediction in large-scale clinical data with rare event outcomes a case study in suicide risk prediction.pdf (10 páginas)\n",
      "  OK: Who Owns the Data? Open Data for Healthcare.pdf (6 páginas)\n",
      "  OK: A Stakeholder-Informed Ethical Framework to Guide Implementation of Suicide Risk Prediction Models Derived from Electronic Health Records.pdf (15 páginas)\n",
      "  OK: Big data governance of personal health information and challenges to contextual integrity.pdf (17 páginas)\n",
      "  OK: Data Science in Healthcare Benefits Challenges and Opportunities.pdf (36 páginas)\n",
      "  OK: The Ethics of Big Data.pdf (36 páginas)\n",
      "  OK: Values challenges and future directions of big data analytics in healthcare A systematic review.pdf (9 páginas)\n",
      "  OK: ETHICS AND GOVERNANCE OF ARTIFICIAL INTELLIGENCE FOR HEALTH.pdf (165 páginas)\n",
      "  OK: Preventing suicide A global imperative.pdf (92 páginas)\n",
      "\n",
      "Procesando: Perspectivas Salud Pública y Comunitaria\n",
      "  OK: A Public Health, Whole of Government Approach to National Suicide Prevention Strategies.pdf (8 páginas)\n",
      "  OK: Suicide Postvention Service Models and Guidelines.pdf (22 páginas)\n",
      "  OK: The social determinants of suicide.pdf (30 páginas)\n",
      "  OK: Characteristics of surveillance systems for suicide and self harm A scoping review.pdf (15 páginas)\n",
      "  OK: Guia comunicacional prevencion del suicidio en medios.pdf (39 páginas)\n",
      "  OK: Real-Time Suicide Surveillance  Comparison of International Surveillance Systems and Recommended Best Practice.pdf (28 páginas)\n",
      "  OK: Gatekeeper training for suicidal behaviors.pdf (9 páginas)\n",
      "  OK: Effectiveness of suicide prevention interventions A systematic review and meta analysis.pdf (14 páginas)\n",
      "  OK: Preventing-suicide--a-public-health-approach-to-a-.pdf (9 páginas)\n",
      "\n",
      "Extracción completada en 34.0 segundos\n",
      "Documentos procesados exitosamente: 29\n"
     ]
    }
   ],
   "source": [
    "# Extraer texto de todos los documentos\n",
    "all_documents = []\n",
    "failed_documents = []\n",
    "\n",
    "print(\"Iniciando extracción de texto...\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "for category_key, category_data in all_pdfs.items():\n",
    "    category_name = category_data[\"name\"]\n",
    "    print(f\"Procesando: {category_name}\")\n",
    "    \n",
    "    for pdf_path in category_data[\"files\"]:\n",
    "        text, metadata = extract_text_from_pdf(pdf_path, category_key, category_name)\n",
    "        \n",
    "        if text:\n",
    "            all_documents.append({\n",
    "                \"text\": text,\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "            print(f\"  OK: {pdf_path.name} ({metadata['num_pages']} páginas)\")\n",
    "        else:\n",
    "            failed_documents.append(pdf_path.name)\n",
    "    \n",
    "    print()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Extracción completada en {elapsed_time:.1f} segundos\")\n",
    "print(f\"Documentos procesados exitosamente: {len(all_documents)}\")\n",
    "if failed_documents:\n",
    "    print(f\"Documentos con errores: {len(failed_documents)}\")\n",
    "    for doc in failed_documents:\n",
    "        print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de la Colección\n",
    "\n",
    "Estadísticas de los documentos procesados para estimar costos y validar la extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando colección...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Enfoques Clínicos y Sistemas de Salud:\n",
      "  Documentos: 10\n",
      "  Páginas totales: 1474\n",
      "  Tokens: 1,117,989\n",
      "\n",
      "Fundamentos Éticos y Gobernanza de Datos:\n",
      "  Documentos: 10\n",
      "  Páginas totales: 398\n",
      "  Tokens: 306,762\n",
      "\n",
      "Perspectivas Salud Pública y Comunitaria:\n",
      "  Documentos: 9\n",
      "  Páginas totales: 174\n",
      "  Tokens: 170,474\n",
      "\n",
      "======================================================================\n",
      "\n",
      "TOTALES:\n",
      "  Documentos: 29\n",
      "  Páginas: 2046\n",
      "  Caracteres: 6,503,177\n",
      "  Tokens: 1,595,225\n",
      "\n",
      "Costo estimado de embeddings: $0.0319 USD\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Cuenta tokens usando tiktoken.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Calcular estadísticas\n",
    "total_characters = 0\n",
    "total_tokens = 0\n",
    "total_pages = 0\n",
    "\n",
    "stats_by_category = {}\n",
    "\n",
    "print(\"Analizando colección...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for doc in all_documents:\n",
    "    text = doc[\"text\"]\n",
    "    metadata = doc[\"metadata\"]\n",
    "    category = metadata[\"category_key\"]\n",
    "    \n",
    "    tokens = count_tokens(text)\n",
    "    \n",
    "    total_characters += len(text)\n",
    "    total_tokens += tokens\n",
    "    total_pages += metadata[\"num_pages\"]\n",
    "    \n",
    "    # Acumular por categoría\n",
    "    if category not in stats_by_category:\n",
    "        stats_by_category[category] = {\n",
    "            \"name\": metadata[\"category_name\"],\n",
    "            \"docs\": 0,\n",
    "            \"tokens\": 0,\n",
    "            \"pages\": 0\n",
    "        }\n",
    "    \n",
    "    stats_by_category[category][\"docs\"] += 1\n",
    "    stats_by_category[category][\"tokens\"] += tokens\n",
    "    stats_by_category[category][\"pages\"] += metadata[\"num_pages\"]\n",
    "\n",
    "# Mostrar estadísticas por categoría\n",
    "for category, stats in stats_by_category.items():\n",
    "    print(f\"\\n{stats['name']}:\")\n",
    "    print(f\"  Documentos: {stats['docs']}\")\n",
    "    print(f\"  Páginas totales: {stats['pages']}\")\n",
    "    print(f\"  Tokens: {stats['tokens']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nTOTALES:\")\n",
    "print(f\"  Documentos: {len(all_documents)}\")\n",
    "print(f\"  Páginas: {total_pages}\")\n",
    "print(f\"  Caracteres: {total_characters:,}\")\n",
    "print(f\"  Tokens: {total_tokens:,}\")\n",
    "\n",
    "# Estimación de costos\n",
    "embedding_cost = (total_tokens / 1_000_000) * 0.02\n",
    "print(f\"\\nCosto estimado de embeddings: ${embedding_cost:.4f} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chunking de Documentos\n",
    "\n",
    "División de los documentos en fragmentos optimizados para búsqueda semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración del chunking:\n",
      "  Tamaño del chunk: 1000 caracteres\n",
      "  Overlap: 200 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Configuración del chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(\"Configuración del chunking:\")\n",
    "print(f\"  Tamaño del chunk: 1000 caracteres\")\n",
    "print(f\"  Overlap: 200 caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creando chunks...\n",
      "\n",
      "Total de chunks creados: 8209\n",
      "Promedio de chunks por documento: 283.1\n"
     ]
    }
   ],
   "source": [
    "# Crear chunks de todos los documentos\n",
    "all_chunks = []\n",
    "\n",
    "print(\"\\nCreando chunks...\\n\")\n",
    "\n",
    "for doc in all_documents:\n",
    "    text = doc[\"text\"]\n",
    "    metadata = doc[\"metadata\"]\n",
    "    \n",
    "    # Dividir en chunks\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Crear objetos Document con metadata\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"source\": metadata[\"filename\"],\n",
    "                \"category\": metadata[\"category_key\"],\n",
    "                \"category_name\": metadata[\"category_name\"],\n",
    "                \"chunk_id\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"num_pages\": metadata[\"num_pages\"]\n",
    "            }\n",
    "        )\n",
    "        all_chunks.append(chunk_doc)\n",
    "\n",
    "print(f\"Total de chunks creados: {len(all_chunks)}\")\n",
    "print(f\"Promedio de chunks por documento: {len(all_chunks) / len(all_documents):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creación del Vector Store\n",
    "\n",
    "Generación de embeddings y almacenamiento en ChromaDB para búsqueda semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings configurados: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "# Configurar embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "print(\"Embeddings configurados: text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio del vector store: /Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/data/chroma_db/production\n",
      "\n",
      "Creando vector store con 8209 chunks...\n",
      "Este proceso puede tomar 3-5 minutos...\n",
      "\n",
      "Vector store creado exitosamente\n",
      "Tiempo de procesamiento: 66.7 segundos\n",
      "Colección: cuidar_rag_production\n",
      "Chunks indexados: 8209\n",
      "Ubicación: /Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/data/chroma_db/production\n"
     ]
    }
   ],
   "source": [
    "# Crear directorio para el vector store de producción\n",
    "chroma_dir = project_root / \"data/chroma_db/production\"\n",
    "chroma_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio del vector store: {chroma_dir}\")\n",
    "print(f\"\\nCreando vector store con {len(all_chunks)} chunks...\")\n",
    "print(\"Este proceso puede tomar 3-5 minutos...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=str(chroma_dir),\n",
    "        collection_name=\"cuidar_rag_production\"\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Vector store creado exitosamente\")\n",
    "    print(f\"Tiempo de procesamiento: {elapsed_time:.1f} segundos\")\n",
    "    print(f\"Colección: cuidar_rag_production\")\n",
    "    print(f\"Chunks indexados: {len(all_chunks)}\")\n",
    "    print(f\"Ubicación: {chroma_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al crear vector store: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validación del Sistema\n",
    "\n",
    "Pruebas para verificar que el vector store funciona correctamente con la colección completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever configurado\n",
      "  Tipo de búsqueda: Similarity\n",
      "  Top K resultados: 5\n"
     ]
    }
   ],
   "source": [
    "# Configurar retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # Aumentamos a 5 para más contexto\n",
    ")\n",
    "\n",
    "print(\"Retriever configurado\")\n",
    "print(\"  Tipo de búsqueda: Similarity\")\n",
    "print(\"  Top K resultados: 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando consultas de validación...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Consulta 1: ¿Qué consideraciones éticas existen para el uso de IA en predicción del suicidio?\n",
      "----------------------------------------------------------------------\n",
      "Resultados encontrados: 5\n",
      "Categorías representadas: 2\n",
      "  - Fundamentos Éticos y Gobernanza de Datos\n",
      "  - Enfoques Clínicos y Sistemas de Salud\n",
      "Documentos únicos: 2\n",
      "\n",
      "Consulta 2: ¿Cuáles son las intervenciones más efectivas en prevención del suicidio según la evidencia?\n",
      "----------------------------------------------------------------------\n",
      "Resultados encontrados: 5\n",
      "Categorías representadas: 1\n",
      "  - Perspectivas Salud Pública y Comunitaria\n",
      "Documentos únicos: 2\n",
      "\n",
      "Consulta 3: ¿Cómo implementar screening de riesgo suicida en atención primaria?\n",
      "----------------------------------------------------------------------\n",
      "Resultados encontrados: 5\n",
      "Categorías representadas: 1\n",
      "  - Enfoques Clínicos y Sistemas de Salud\n",
      "Documentos únicos: 1\n",
      "\n",
      "Consulta 4: ¿Qué indicadores se recomiendan para evaluar programas de prevención del suicidio?\n",
      "----------------------------------------------------------------------\n",
      "Resultados encontrados: 5\n",
      "Categorías representadas: 1\n",
      "  - Perspectivas Salud Pública y Comunitaria\n",
      "Documentos únicos: 2\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Validación completada\n"
     ]
    }
   ],
   "source": [
    "# Consultas de validación\n",
    "validation_queries = [\n",
    "    \"¿Qué consideraciones éticas existen para el uso de IA en predicción del suicidio?\",\n",
    "    \"¿Cuáles son las intervenciones más efectivas en prevención del suicidio según la evidencia?\",\n",
    "    \"¿Cómo implementar screening de riesgo suicida en atención primaria?\",\n",
    "    \"¿Qué indicadores se recomiendan para evaluar programas de prevención del suicidio?\"\n",
    "]\n",
    "\n",
    "print(\"Ejecutando consultas de validación...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, query in enumerate(validation_queries, 1):\n",
    "    print(f\"\\nConsulta {i}: {query}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    # Mostrar fuentes encontradas\n",
    "    sources = set()\n",
    "    categories = set()\n",
    "    \n",
    "    for doc in results:\n",
    "        sources.add(doc.metadata['source'])\n",
    "        categories.add(doc.metadata['category_name'])\n",
    "    \n",
    "    print(f\"Resultados encontrados: {len(results)}\")\n",
    "    print(f\"Categorías representadas: {len(categories)}\")\n",
    "    for cat in categories:\n",
    "        print(f\"  - {cat}\")\n",
    "    print(f\"Documentos únicos: {len(sources)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nValidación completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prueba del RAG Completo\n",
    "\n",
    "Validación del pipeline completo con generación de respuestas en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente de OpenAI y prompt configurados\n"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente de OpenAI\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Prompt del sistema\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Eres un asistente experto en prevención del suicidio, gobernanza de datos y políticas públicas de salud mental.\n",
    "\n",
    "Tu rol es apoyar a equipos de gobiernos locales y servicios de salud en la toma de decisiones basadas en evidencia para la prevención del suicidio.\n",
    "\n",
    "Instrucciones:\n",
    "1. Responde siempre en español, de forma clara y profesional.\n",
    "2. Basa tus respuestas en el contexto proporcionado (documentos científicos y guías).\n",
    "3. Cita las fuentes cuando sea relevante (nombre del documento).\n",
    "4. Si la información del contexto es insuficiente, indícalo claramente.\n",
    "5. Cuando sea pertinente, sugiere que el usuario considere investigación o datos locales para complementar las recomendaciones.\n",
    "6. Mantén un tono técnico pero accesible para tomadores de decisiones.\n",
    "7. Prioriza recomendaciones prácticas y accionables.\n",
    "\n",
    "Recuerda: Tu objetivo es facilitar el uso efectivo de datos para la prevención del suicidio, alineado con las dimensiones del índice CUIDAR (Accesibilidad, Calidad, Interoperabilidad, Uso, Capacidad Analítica, Gestión del Conocimiento, Ética y Gobernanza).\n",
    "\"\"\"\n",
    "\n",
    "print(\"Cliente de OpenAI y prompt configurados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función generate_rag_response definida\n"
     ]
    }
   ],
   "source": [
    "def generate_rag_response(query, retriever, client, k=5):\n",
    "    \"\"\"\n",
    "    Genera una respuesta utilizando RAG.\n",
    "    \"\"\"\n",
    "    # Recuperar chunks relevantes\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return {\n",
    "            \"respuesta\": \"No encontré información relevante en la base de conocimiento.\",\n",
    "            \"fuentes\": [],\n",
    "            \"chunks_utilizados\": 0\n",
    "        }\n",
    "    \n",
    "    # Construir contexto\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        source_name = doc.metadata.get('source', 'Fuente desconocida')\n",
    "        context_parts.append(f\"[Documento {i} - {source_name}]:\\n{doc.page_content}\")\n",
    "        \n",
    "        if source_name not in sources:\n",
    "            sources.append(source_name)\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Prompt del usuario\n",
    "    user_prompt = f\"\"\"Contexto (documentos recuperados):\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Pregunta: {query}\n",
    "\n",
    "Responde basándote en el contexto. Si sería útil contar con datos locales, menciónalo.\"\"\"\n",
    "    \n",
    "    # Generar respuesta\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1200\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"respuesta\": response.choices[0].message.content,\n",
    "            \"fuentes\": sources,\n",
    "            \"chunks_utilizados\": len(retrieved_docs),\n",
    "            \"tokens_utilizados\": response.usage.total_tokens\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"respuesta\": f\"Error: {str(e)}\",\n",
    "            \"fuentes\": sources,\n",
    "            \"chunks_utilizados\": len(retrieved_docs)\n",
    "        }\n",
    "\n",
    "print(\"Función generate_rag_response definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando prueba del RAG completo...\n",
      "\n",
      "======================================================================\n",
      "CONSULTA: ¿Cuáles son las intervenciones más efectivas para la prevención del suicidio según la evidencia científica?\n",
      "======================================================================\n",
      "\n",
      "RESPUESTA:\n",
      "\n",
      "Las intervenciones más efectivas para la prevención del suicidio, según la evidencia científica, abarcan una variedad de enfoques que pueden ser implementados en los niveles comunitario, institucional y mediático. A continuación, se presentan algunas de las estrategias más destacadas:\n",
      "\n",
      "1. **Mejora de la comunicación mediática**: La implementación de directrices para los medios de comunicación es fundamental. Estas directrices deben incluir la forma en que se reporta sobre el suicidio, evitando la glorificación y el sensacionalismo, y promoviendo narrativas de esperanza y recuperación. Estudios han demostrado que una cobertura responsable puede reducir el riesgo de imitación del suicidio (Documento 1, 2 y 5).\n",
      "\n",
      "2. **Educación y sensibilización**: La difusión de información adecuada sobre la salud mental y la prevención del suicidio es esencial. Esto incluye la promoción de relatos de recuperación y resiliencia, que han mostrado tener efectos protectores, especialmente en poblaciones vulnerables como jóvenes y personas LGBTQI+ (Documento 3 y 4).\n",
      "\n",
      "3. **Acceso a servicios de salud mental**: Asegurar que las personas tengan acceso a servicios de salud mental de calidad es crucial. Esto implica la evaluación oportuna de problemas de salud mental y su manejo eficaz, así como la capacitación de profesionales para identificar y tratar adecuadamente a personas en riesgo (Documento 2).\n",
      "\n",
      "4. **Restricción de medios de suicidio**: Implementar políticas que limiten el acceso a métodos letales de suicidio ha demostrado ser una estrategia efectiva. Esto puede incluir la regulación de sustancias y la modificación de entornos que faciliten el suicidio (Documento 2).\n",
      "\n",
      "5. **Intervenciones comunitarias**: Promover programas comunitarios que fomenten la cohesión social y el apoyo entre pares puede ser beneficioso. Las intervenciones que involucran a la comunidad en la identificación y apoyo a individuos en riesgo son clave para la prevención (Documento 2).\n",
      "\n",
      "6. **Monitoreo y evaluación**: La recopilación y análisis de datos sobre suicidio y comportamientos relacionados son esenciales para entender las tendencias locales y evaluar la efectividad de las intervenciones implementadas. Esto se alinea con la dimensión de \"Uso\" y \"Capacidad Analítica\" del índice CUIDAR.\n",
      "\n",
      "Es importante considerar que la efectividad de estas intervenciones puede variar según el contexto cultural, local y demográfico. Por lo tanto, sería útil contar con datos locales que permitan adaptar estas recomendaciones a las necesidades específicas de la población en cuestión. Además, la colaboración con expertos en salud mental y organizaciones comunitarias puede enriquecer el enfoque y asegurar que las intervenciones sean pertinentes y efectivas.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "FUENTES UTILIZADAS:\n",
      "  1. Guia comunicacional prevencion del suicidio en medios.pdf\n",
      "\n",
      "Chunks recuperados: 5\n",
      "Tokens utilizados: 2037\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba del RAG completo\n",
    "test_query = \"¿Cuáles son las intervenciones más efectivas para la prevención del suicidio según la evidencia científica?\"\n",
    "\n",
    "print(\"Ejecutando prueba del RAG completo...\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"CONSULTA: {test_query}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = generate_rag_response(test_query, retriever, client)\n",
    "\n",
    "print(\"\\nRESPUESTA:\\n\")\n",
    "print(result[\"respuesta\"])\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nFUENTES UTILIZADAS:\")\n",
    "for i, source in enumerate(result[\"fuentes\"], 1):\n",
    "    print(f\"  {i}. {source}\")\n",
    "print(f\"\\nChunks recuperados: {result['chunks_utilizados']}\")\n",
    "if \"tokens_utilizados\" in result:\n",
    "    print(f\"Tokens utilizados: {result['tokens_utilizados']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar Configuración de Producción\n",
    "\n",
    "Exporto la configuración y estadísticas del sistema para referencia futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración guardada en: /Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/data/rag_production_config.json\n",
      "\n",
      "Resumen de la configuración:\n",
      "{\n",
      "  \"fecha_creacion\": \"2025-11-18T10:29:40.150880\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"documentos\": {\n",
      "    \"total\": 29,\n",
      "    \"por_categoria\": {\n",
      "      \"clinical\": 10,\n",
      "      \"ethics\": 10,\n",
      "      \"public_health\": 9\n",
      "    }\n",
      "  },\n",
      "  \"chunks\": {\n",
      "    \"total\": 8209,\n",
      "    \"chunk_size\": 1000,\n",
      "    \"chunk_overlap\": 200\n",
      "  },\n",
      "  \"tokens_totales\": 1595225,\n",
      "  \"vectorstore\": {\n",
      "    \"tipo\": \"ChromaDB\",\n",
      "    \"coleccion\": \"cuidar_rag_production\",\n",
      "    \"ubicacion\": \"/Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/data/chroma_db/production\",\n",
      "    \"embedding_model\": \"text-embedding-3-small\"\n",
      "  },\n",
      "  \"retriever\": {\n",
      "    \"search_type\": \"similarity\",\n",
      "    \"k\": 5\n",
      "  },\n",
      "  \"generation\": {\n",
      "    \"modelo\": \"gpt-4o-mini\",\n",
      "    \"temperatura\": 0.3,\n",
      "    \"max_tokens\": 1200\n",
      "  },\n",
      "  \"categorias\": [\n",
      "    \"Enfoques Clínicos y Sistemas de Salud\",\n",
      "    \"Fundamentos Éticos y Gobernanza de Datos\",\n",
      "    \"Perspectivas Salud Pública y Comunitaria\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Crear resumen de producción\n",
    "production_config = {\n",
    "    \"fecha_creacion\": datetime.now().isoformat(),\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"documentos\": {\n",
    "        \"total\": len(all_documents),\n",
    "        \"por_categoria\": {k: v[\"docs\"] for k, v in stats_by_category.items()}\n",
    "    },\n",
    "    \"chunks\": {\n",
    "        \"total\": len(all_chunks),\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200\n",
    "    },\n",
    "    \"tokens_totales\": total_tokens,\n",
    "    \"vectorstore\": {\n",
    "        \"tipo\": \"ChromaDB\",\n",
    "        \"coleccion\": \"cuidar_rag_production\",\n",
    "        \"ubicacion\": str(chroma_dir),\n",
    "        \"embedding_model\": \"text-embedding-3-small\"\n",
    "    },\n",
    "    \"retriever\": {\n",
    "        \"search_type\": \"similarity\",\n",
    "        \"k\": 5\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"modelo\": \"gpt-4o-mini\",\n",
    "        \"temperatura\": 0.3,\n",
    "        \"max_tokens\": 1200\n",
    "    },\n",
    "    \"categorias\": [v[\"name\"] for v in stats_by_category.values()]\n",
    "}\n",
    "\n",
    "# Guardar configuración\n",
    "config_path = project_root / \"data/rag_production_config.json\"\n",
    "with open(config_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(production_config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Configuración guardada en: {config_path}\")\n",
    "print(\"\\nResumen de la configuración:\")\n",
    "print(json.dumps(production_config, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Conclusiones\n",
    "\n",
    "### Resultados\n",
    "\n",
    "Sistema RAG de producción creado exitosamente con:\n",
    "- 30 documentos procesados de 3 categorías temáticas\n",
    "- Vector store optimizado para búsqueda semántica\n",
    "- Pipeline de generación validado\n",
    "\n",
    "### Próximos Pasos\n",
    "\n",
    "1. **Implementar interfaz Streamlit** con:\n",
    "   - Chat interactivo\n",
    "   - Subida de documentos locales\n",
    "   - Integración con CUIDAR Index\n",
    "\n",
    "2. **Optimizaciones futuras**:\n",
    "   - Implementar caché de respuestas\n",
    "   - Agregar filtros por categoría\n",
    "   - Mejorar ranking de resultados\n",
    "\n",
    "### Uso del Vector Store\n",
    "\n",
    "Para cargar el vector store en otros notebooks o en Streamlit:\n",
    "\n",
    "```python\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"data/chroma_db/production\",\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"cuidar_rag_production\"\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuidar (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
