{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Notebook 1: Test de Analizadores Individuales\n",
    "\n",
    "Este notebook permite probar cada analizador por separado para entender c√≥mo funcionan.\n",
    "\n",
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports exitosos\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Agregar ruta del proyecto\n",
    "sys.path.append('..')\n",
    "\n",
    "from fase3_evaluator.analyzers import (\n",
    "    analyze_completeness,\n",
    "    analyze_typology,\n",
    "    analyze_semantic,\n",
    "    analyze_geospatial,\n",
    "    analyze_anonymization,\n",
    "    analyze_ml_readiness\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports exitosos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Dataset de Prueba\n",
    "\n",
    "Generamos un dataset sint√©tico con problemas t√≠picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creado: 20 registros, 9 columnas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha_evento</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>metodo</th>\n",
       "      <th>municipio</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>tipo_evento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>25.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ahorcamiento</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>40.4168</td>\n",
       "      <td>-3.7038</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>30.0</td>\n",
       "      <td>F</td>\n",
       "      <td>intoxicacion</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>39.4699</td>\n",
       "      <td>-0.3763</td>\n",
       "      <td>intento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>40.4168</td>\n",
       "      <td>-3.7038</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>arma fuego</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>150.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ahorcamiento</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>41.3851</td>\n",
       "      <td>2.1734</td>\n",
       "      <td>intento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id fecha_evento   edad sexo        metodo  municipio  latitud  longitud  \\\n",
       "0   1   2024-01-07   25.0    M  ahorcamiento     Madrid  40.4168   -3.7038   \n",
       "1   2   2024-01-14   30.0    F  intoxicacion   Valencia  39.4699   -0.3763   \n",
       "2   3   2024-01-21    NaN    M          None     Madrid  40.4168   -3.7038   \n",
       "3   4   2024-01-28   45.0    M    arma fuego       None      NaN       NaN   \n",
       "4   5   2024-02-04  150.0    F  ahorcamiento  Barcelona  41.3851    2.1734   \n",
       "\n",
       "  tipo_evento  \n",
       "0   consumado  \n",
       "1     intento  \n",
       "2   consumado  \n",
       "3   consumado  \n",
       "4     intento  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset de prueba con problemas t√≠picos\n",
    "df = pd.DataFrame({\n",
    "    'id': range(1, 21),\n",
    "    'fecha_evento': pd.date_range('2024-01-01', periods=20, freq='W'),\n",
    "    'edad': [25, 30, None, 45, 150, 52, 38, None, 60, 28, \n",
    "             35, 42, 29, None, 55, 48, 33, 41, 37, 44],\n",
    "    'sexo': ['M', 'F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'F',\n",
    "             'M', 'F', 'M', 'M', 'F', 'M', 'F', 'M', 'F', 'M'],\n",
    "    'metodo': ['ahorcamiento', 'intoxicacion', None, 'arma fuego', 'ahorcamiento',\n",
    "               'precipitacion', 'ahorcadura', 'intoxicacion', 'arma de fuego', None,\n",
    "               'ahorcamiento', 'sobredosis', 'colgamiento', 'arma fuego', 'intoxicacion',\n",
    "               'ahorcamiento', 'precipitacion', 'disparo', 'envenenamiento', 'ahorcamiento'],\n",
    "    'municipio': ['Madrid', 'Valencia', 'Madrid', None, 'Barcelona',\n",
    "                  'Sevilla', 'Madrid', 'Valencia', 'Barcelona', 'Madrid',\n",
    "                  'Valencia', 'Madrid', None, 'Barcelona', 'Valencia',\n",
    "                  'Madrid', 'Sevilla', 'Barcelona', 'Madrid', 'Valencia'],\n",
    "    'latitud': [40.4168, 39.4699, 40.4168, None, 41.3851,\n",
    "                37.3891, 40.4168, 39.4699, 41.3851, 40.4168,\n",
    "                39.4699, 40.4168, None, 41.3851, 39.4699,\n",
    "                40.4168, 37.3891, 41.3851, 40.4168, 39.4699],\n",
    "    'longitud': [-3.7038, -0.3763, -3.7038, None, 2.1734,\n",
    "                 -5.9845, -3.7038, -0.3763, 2.1734, -3.7038,\n",
    "                 -0.3763, -3.7038, None, 2.1734, -0.3763,\n",
    "                 -3.7038, -5.9845, 2.1734, -3.7038, -0.3763],\n",
    "    'tipo_evento': ['consumado', 'intento', 'consumado', 'consumado', 'intento',\n",
    "                    'consumado', 'intento', 'intento', 'consumado', 'intento',\n",
    "                    'consumado', 'intento', 'consumado', 'consumado', 'intento',\n",
    "                    'consumado', 'intento', 'consumado', 'intento', 'consumado']\n",
    "})\n",
    "\n",
    "print(f\"Dataset creado: {len(df)} registros, {len(df.columns)} columnas\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Test: Analizador de Completitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN DE COMPLETITUD\n",
      "============================================================\n",
      "Total de celdas: 180\n",
      "Celdas faltantes: 11\n",
      "Porcentaje faltante: 6.11%\n",
      "\n",
      "Score: 93.9/100\n",
      "Nivel: excelente\n",
      "\n",
      "Campos cr√≠ticos faltantes: []\n",
      "\n",
      "üìä Top columnas con valores faltantes:\n",
      "  - edad: 15.0%\n",
      "  - metodo: 10.0%\n",
      "  - municipio: 10.0%\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis de completitud\n",
    "result_completeness = analyze_completeness(df)\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DE COMPLETITUD\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total de celdas: {result_completeness['summary']['total_cells']}\")\n",
    "print(f\"Celdas faltantes: {result_completeness['summary']['missing_cells']}\")\n",
    "print(f\"Porcentaje faltante: {result_completeness['summary']['missing_percentage']:.2f}%\")\n",
    "print(f\"\\nScore: {result_completeness['evaluation']['score']:.1f}/100\")\n",
    "print(f\"Nivel: {result_completeness['evaluation']['level']}\")\n",
    "print(f\"\\nCampos cr√≠ticos faltantes: {result_completeness['critical_fields_missing']}\")\n",
    "\n",
    "# Top columnas con m√°s faltantes\n",
    "print(\"\\nüìä Top columnas con valores faltantes:\")\n",
    "for col_info in result_completeness['top_missing_columns'][:3]:\n",
    "    print(f\"  - {col_info['column']}: {col_info['missing_rate']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Test: Analizador de Tipolog√≠a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISIS DE TIPOLOG√çA\n",
      "============================================================\n",
      "Total columnas: 9\n",
      "Inconsistencias: 1\n",
      "Problemas de encoding: 0\n",
      "\n",
      "Score de calidad: 95.6/100\n",
      "\n",
      "‚ö†Ô∏è Inconsistencias detectadas:\n",
      "  - Columna 'sexo':\n",
      "    Esperado: string_categorical\n",
      "    Encontrado: ['string_categorical', 'string_boolean']\n",
      "    Tasa de inconsistencia: 45.0%\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis de tipolog√≠a\n",
    "result_typology = analyze_typology(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE TIPOLOG√çA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total columnas: {result_typology['summary']['total_columns']}\")\n",
    "print(f\"Inconsistencias: {result_typology['summary']['inconsistencies_count']}\")\n",
    "print(f\"Problemas de encoding: {result_typology['summary']['encoding_issues_count']}\")\n",
    "print(f\"\\nScore de calidad: {result_typology['summary']['quality_score']:.1f}/100\")\n",
    "\n",
    "# Mostrar inconsistencias detectadas\n",
    "if result_typology['inconsistencies']:\n",
    "    print(\"\\n‚ö†Ô∏è Inconsistencias detectadas:\")\n",
    "    for issue in result_typology['inconsistencies'][:3]:\n",
    "        print(f\"  - Columna '{issue['column']}':\")\n",
    "        print(f\"    Esperado: {issue['expected']}\")\n",
    "        print(f\"    Encontrado: {issue['found']}\")\n",
    "        print(f\"    Tasa de inconsistencia: {issue['inconsistency_rate']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Test: Analizador Sem√°ntico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISIS SEM√ÅNTICO\n",
      "============================================================\n",
      "Total de issues: 7\n",
      "Issues cr√≠ticos: 1\n",
      "Score: 76.0/100\n",
      "Nivel de calidad: bueno\n",
      "\n",
      "‚ö†Ô∏è Edades inv√°lidas detectadas: 1\n",
      "  - Fila 4: edad=150.0 (Edad superior a 120 a√±os)\n",
      "\n",
      "üìã M√©todos no estandarizados: 6\n",
      "  - 'arma fuego' (n=2) ‚Üí sugerir: 'arma de fuego'\n",
      "  - 'ahorcadura' (n=1) ‚Üí sugerir: 'ahorcamiento'\n",
      "  - 'sobredosis' (n=1) ‚Üí sugerir: 'intoxicacion'\n",
      "  - 'colgamiento' (n=1) ‚Üí sugerir: 'ahorcamiento'\n",
      "  - 'disparo' (n=1) ‚Üí sugerir: 'arma de fuego'\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis sem√°ntico\n",
    "result_semantic = analyze_semantic(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS SEM√ÅNTICO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total de issues: {result_semantic['summary']['total_issues']}\")\n",
    "print(f\"Issues cr√≠ticos: {result_semantic['summary']['critical_issues']}\")\n",
    "print(f\"Score: {result_semantic['summary']['score']:.1f}/100\")\n",
    "print(f\"Nivel de calidad: {result_semantic['summary']['quality_level']}\")\n",
    "\n",
    "# Edades inv√°lidas\n",
    "if result_semantic['edad_invalida']:\n",
    "    print(f\"\\n‚ö†Ô∏è Edades inv√°lidas detectadas: {len(result_semantic['edad_invalida'])}\")\n",
    "    for issue in result_semantic['edad_invalida'][:3]:\n",
    "        print(f\"  - Fila {issue['row']}: edad={issue['value']} ({issue['issue']})\")\n",
    "\n",
    "# M√©todos no estandarizados\n",
    "if result_semantic['metodos_no_estandarizados']:\n",
    "    print(f\"\\nüìã M√©todos no estandarizados: {len(result_semantic['metodos_no_estandarizados'])}\")\n",
    "    for method in result_semantic['metodos_no_estandarizados'][:5]:\n",
    "        print(f\"  - '{method['value']}' (n={method['count']}) ‚Üí sugerir: '{method['suggestion']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Test: Analizador Geoespacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISIS GEOESPACIAL\n",
      "============================================================\n",
      "Geocodificable: S√≠\n",
      "Cobertura: 90.0%\n",
      "Calidad: excelente\n",
      "Score: 90.0/100\n",
      "M√©todo: coordenadas_directas\n",
      "\n",
      "üó∫Ô∏è Clustering espacial:\n",
      "  Factible: No\n",
      "\n",
      "üìç Coordenadas:\n",
      "  Pares v√°lidos: 18/20\n",
      "  Cobertura: 90.0%\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis geoespacial\n",
    "result_geospatial = analyze_geospatial(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS GEOESPACIAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Geocodificable: {'S√≠' if result_geospatial['summary']['geocodable'] else 'No'}\")\n",
    "print(f\"Cobertura: {result_geospatial['summary']['coverage']*100:.1f}%\")\n",
    "print(f\"Calidad: {result_geospatial['summary']['quality']}\")\n",
    "print(f\"Score: {result_geospatial['summary']['score']:.1f}/100\")\n",
    "print(f\"M√©todo: {result_geospatial['summary']['primary_method']}\")\n",
    "\n",
    "# Clustering\n",
    "print(f\"\\nüó∫Ô∏è Clustering espacial:\")\n",
    "print(f\"  Factible: {'S√≠' if result_geospatial['clustering_potential']['feasible'] else 'No'}\")\n",
    "if result_geospatial['clustering_potential']['feasible']:\n",
    "    print(f\"  Algoritmos recomendados: {', '.join(result_geospatial['clustering_potential']['recommended_algorithms'])}\")\n",
    "\n",
    "# Coordenadas\n",
    "if result_geospatial['coordinates_analysis']:\n",
    "    coords = result_geospatial['coordinates_analysis']\n",
    "    print(f\"\\nüìç Coordenadas:\")\n",
    "    print(f\"  Pares v√°lidos: {coords['valid_pairs']}/{coords['total_records']}\")\n",
    "    print(f\"  Cobertura: {coords['coverage']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Test: Analizador de Anonimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISIS DE ANONIMIZACI√ìN\n",
      "============================================================\n",
      "PII detectada: S√≠\n",
      "Risk score: 3.3/10\n",
      "Nivel de riesgo: moderado\n",
      "Cr√≠tico: No\n",
      "\n",
      "‚ö†Ô∏è Entidades PII encontradas:\n",
      "  - ID_NUMBER en 'id': 20 instancias\n",
      "    Contribuci√≥n al riesgo: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis de anonimizaci√≥n\n",
    "result_anonymization = analyze_anonymization(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE ANONIMIZACI√ìN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PII detectada: {'S√≠' if result_anonymization['summary']['pii_detected'] else 'No'}\")\n",
    "print(f\"Risk score: {result_anonymization['risk_assessment']['score']:.1f}/10\")\n",
    "print(f\"Nivel de riesgo: {result_anonymization['risk_assessment']['level']}\")\n",
    "print(f\"Cr√≠tico: {'S√≠' if result_anonymization['risk_assessment']['critical'] else 'No'}\")\n",
    "\n",
    "if result_anonymization['entities_found']:\n",
    "    print(f\"\\n‚ö†Ô∏è Entidades PII encontradas:\")\n",
    "    for entity in result_anonymization['entities_found']:\n",
    "        print(f\"  - {entity['type']} en '{entity['column']}': {entity['count']} instancias\")\n",
    "        print(f\"    Contribuci√≥n al riesgo: {entity['risk_contribution']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Test: Analizador ML Readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISIS ML READINESS\n",
      "============================================================\n",
      "ML viable: No\n",
      "Confianza: nula\n",
      "Score: 50.0/100\n",
      "\n",
      "Target detectado: tipo_evento\n",
      "\n",
      "üìä Features:\n",
      "  Total features potenciales: 6\n",
      "  Features usables: 6\n",
      "  Num√©ricas: 3\n",
      "  Categ√≥ricas: 2\n",
      "\n",
      "‚öñÔ∏è Balance de clases:\n",
      "  Variable: tipo_evento\n",
      "  N√∫mero de clases: 2\n",
      "  Nivel de balance: balanceado\n",
      "  Distribuci√≥n: {'consumado': 11, 'intento': 9}\n",
      "\n",
      "ü§ñ Modelos sugeridos:\n",
      "  - clasificacion_binaria: Logistic Regression, Random Forest, XGBoost\n",
      "    Raz√≥n: Dataset peque√±o - modelos interpretables recomendados\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis ML\n",
    "result_ml = analyze_ml_readiness(df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS ML READINESS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ML viable: {'S√≠' if result_ml['ml_viability']['viable'] else 'No'}\")\n",
    "print(f\"Confianza: {result_ml['ml_viability']['confidence']}\")\n",
    "print(f\"Score: {result_ml['ml_viability']['score']:.1f}/100\")\n",
    "\n",
    "# Target detectado\n",
    "print(f\"\\nTarget detectado: {result_ml['target_column']}\")\n",
    "\n",
    "# Features\n",
    "print(f\"\\nüìä Features:\")\n",
    "print(f\"  Total features potenciales: {result_ml['features_analysis']['potential_features']}\")\n",
    "print(f\"  Features usables: {result_ml['features_analysis']['usable_features']}\")\n",
    "print(f\"  Num√©ricas: {len(result_ml['features_analysis']['numeric_features'])}\")\n",
    "print(f\"  Categ√≥ricas: {len(result_ml['features_analysis']['categorical_features'])}\")\n",
    "\n",
    "# Balance de clases\n",
    "if result_ml['balance_analysis']:\n",
    "    balance = result_ml['balance_analysis']\n",
    "    print(f\"\\n‚öñÔ∏è Balance de clases:\")\n",
    "    print(f\"  Variable: {balance['column']}\")\n",
    "    print(f\"  N√∫mero de clases: {balance['n_classes']}\")\n",
    "    print(f\"  Nivel de balance: {balance['balance_level']}\")\n",
    "    print(f\"  Distribuci√≥n: {balance['class_distribution']}\")\n",
    "\n",
    "# Leakage risks\n",
    "if result_ml['leakage_risks']:\n",
    "    print(f\"\\n‚ö†Ô∏è Riesgos de leakage detectados: {len(result_ml['leakage_risks'])}\")\n",
    "    for risk in result_ml['leakage_risks'][:3]:\n",
    "        print(f\"  - Columna '{risk['column']}': {risk['reason']}\")\n",
    "\n",
    "# Sugerencias de modelos\n",
    "print(f\"\\nü§ñ Modelos sugeridos:\")\n",
    "for suggestion in result_ml['model_suggestions']:\n",
    "    print(f\"  - {suggestion['task']}: {', '.join(suggestion['models'])}\")\n",
    "    print(f\"    Raz√≥n: {suggestion['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Guardar Resultados\n",
    "\n",
    "Opcional: guarda los resultados en JSON para an√°lisis posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion de conversion cargada\n"
     ]
    }
   ],
   "source": [
    "# CELDA NUEVA: Funci√≥n helper para convertir tipos NumPy\n",
    "import numpy as np\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convierte tipos NumPy a tipos nativos Python para JSON serialization\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "print(\"Funcion de conversion cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en: ../data/outputs/test_analizadores_results.json\n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados consolidados\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path('../data/outputs/test_analizadores_results.json')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CONVERTIR ANTES DE GUARDAR\n",
    "all_results_clean = convert_numpy_types(all_results)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_results_clean, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Resultados guardados en: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuidar (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
