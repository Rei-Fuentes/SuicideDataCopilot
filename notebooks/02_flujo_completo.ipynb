{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîÑ Notebook 2: Flujo Completo con Anonimizaci√≥n\n",
    "\n",
    "Este notebook ejecuta el flujo completo:\n",
    "1. Cargar datos\n",
    "2. Ejecutar an√°lisis en paralelo\n",
    "3. Detectar PII\n",
    "4. Anonimizar autom√°ticamente\n",
    "5. Generar diagn√≥stico con LLM\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports exitosos\n",
      "\n",
      "‚öôÔ∏è Configuraci√≥n:\n",
      "  - OpenAI Model: gpt-4o\n",
      "  - Max Workers: 6\n",
      "  - API Key configurada: S√≠\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from fase3_evaluator.integration import (\n",
    "    run_parallel_analysis,\n",
    "    get_analysis_summary\n",
    ")\n",
    "from fase3_evaluator.agent import generate_diagnosis\n",
    "from config import settings\n",
    "\n",
    "print(\"‚úÖ Imports exitosos\")\n",
    "print(f\"\\n‚öôÔ∏è Configuraci√≥n:\")\n",
    "print(f\"  - OpenAI Model: {settings.OPENAI_MODEL}\")\n",
    "print(f\"  - Max Workers: {settings.MAX_WORKERS}\")\n",
    "print(f\"  - API Key configurada: {'S√≠' if settings.OPENAI_API_KEY else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Crear Dataset con PII\n",
    "\n",
    "Creamos un dataset que incluye informaci√≥n sensible para probar la anonimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset creado: 15 registros\n",
      "\n",
      "‚ö†Ô∏è Columnas con PII:\n",
      "  - nombre_completo\n",
      "  - dni\n",
      "  - telefono\n",
      "  - direccion (algunas con direcci√≥n exacta)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/vn5cjqrn391dh43wp7w81j2r0000gn/T/ipykernel_43907/1352713272.py:11: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  'fecha_nacimiento': pd.date_range('1960-01-01', periods=15, freq='2Y'),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_registro</th>\n",
       "      <th>nombre_completo</th>\n",
       "      <th>fecha_nacimiento</th>\n",
       "      <th>fecha_evento</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>dni</th>\n",
       "      <th>telefono</th>\n",
       "      <th>direccion</th>\n",
       "      <th>metodo</th>\n",
       "      <th>municipio</th>\n",
       "      <th>tipo_evento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Juan Garc√≠a L√≥pez</td>\n",
       "      <td>1960-12-31</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>12345678A</td>\n",
       "      <td>666123456</td>\n",
       "      <td>Calle Mayor 123, Madrid</td>\n",
       "      <td>ahorcamiento</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mar√≠a Rodr√≠guez P√©rez</td>\n",
       "      <td>1962-12-31</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>23456789B</td>\n",
       "      <td>677234567</td>\n",
       "      <td>Avenida Principal 45, Valencia</td>\n",
       "      <td>intoxicacion</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>intento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pedro Mart√≠nez S√°nchez</td>\n",
       "      <td>1964-12-31</td>\n",
       "      <td>2024-02-04</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>34567890C</td>\n",
       "      <td>688345678</td>\n",
       "      <td>Plaza Espa√±a 7, Barcelona</td>\n",
       "      <td>arma de fuego</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ana L√≥pez Fern√°ndez</td>\n",
       "      <td>1966-12-31</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>45678901D</td>\n",
       "      <td>None</td>\n",
       "      <td>Calle Real 89, Sevilla</td>\n",
       "      <td>ahorcamiento</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>intento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Carlos S√°nchez Garc√≠a</td>\n",
       "      <td>1968-12-31</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>56789012E</td>\n",
       "      <td>600456789</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>precipitacion</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>consumado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_registro         nombre_completo fecha_nacimiento fecha_evento  edad  \\\n",
       "0            1       Juan Garc√≠a L√≥pez       1960-12-31   2024-01-07    25   \n",
       "1            2   Mar√≠a Rodr√≠guez P√©rez       1962-12-31   2024-01-21    30   \n",
       "2            3  Pedro Mart√≠nez S√°nchez       1964-12-31   2024-02-04    45   \n",
       "3            4     Ana L√≥pez Fern√°ndez       1966-12-31   2024-02-18    52   \n",
       "4            5   Carlos S√°nchez Garc√≠a       1968-12-31   2024-03-03    38   \n",
       "\n",
       "  sexo        dni   telefono                       direccion         metodo  \\\n",
       "0    M  12345678A  666123456         Calle Mayor 123, Madrid   ahorcamiento   \n",
       "1    F  23456789B  677234567  Avenida Principal 45, Valencia   intoxicacion   \n",
       "2    M  34567890C  688345678       Plaza Espa√±a 7, Barcelona  arma de fuego   \n",
       "3    F  45678901D       None          Calle Real 89, Sevilla   ahorcamiento   \n",
       "4    M  56789012E  600456789                          Madrid  precipitacion   \n",
       "\n",
       "   municipio tipo_evento  \n",
       "0     Madrid   consumado  \n",
       "1   Valencia     intento  \n",
       "2  Barcelona   consumado  \n",
       "3    Sevilla     intento  \n",
       "4     Madrid   consumado  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset con PII para probar anonimizaci√≥n\n",
    "df_with_pii = pd.DataFrame({\n",
    "    'id_registro': range(1, 16),\n",
    "    'nombre_completo': [\n",
    "        'Juan Garc√≠a L√≥pez', 'Mar√≠a Rodr√≠guez P√©rez', 'Pedro Mart√≠nez S√°nchez',\n",
    "        'Ana L√≥pez Fern√°ndez', 'Carlos S√°nchez Garc√≠a', 'Laura Fern√°ndez Mart√≠n',\n",
    "        'Miguel P√©rez L√≥pez', 'Isabel Garc√≠a Rodr√≠guez', 'Antonio L√≥pez Mart√≠nez',\n",
    "        'Carmen Mart√≠nez Garc√≠a', 'Jos√© Rodr√≠guez L√≥pez', 'Teresa Garc√≠a P√©rez',\n",
    "        'Francisco L√≥pez S√°nchez', 'Rosa P√©rez Fern√°ndez', 'Manuel S√°nchez Mart√≠n'\n",
    "    ],\n",
    "    'fecha_nacimiento': pd.date_range('1960-01-01', periods=15, freq='2Y'),\n",
    "    'fecha_evento': pd.date_range('2024-01-01', periods=15, freq='2W'),\n",
    "    'edad': [25, 30, 45, 52, 38, 60, 28, 35, 42, 29, 55, 48, 33, 41, 37],\n",
    "    'sexo': ['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M'],\n",
    "    'dni': ['12345678A', '23456789B', '34567890C', '45678901D', '56789012E',\n",
    "            '67890123F', '78901234G', '89012345H', '90123456I', '01234567J',\n",
    "            '12345678K', '23456789L', '34567890M', '45678901N', '56789012O'],\n",
    "    'telefono': ['666123456', '677234567', '688345678', None, '600456789',\n",
    "                 '611567890', '622678901', '633789012', None, '655901234',\n",
    "                 '666012345', '677123456', '688234567', '699345678', '600456789'],\n",
    "    'direccion': [\n",
    "        'Calle Mayor 123, Madrid', 'Avenida Principal 45, Valencia',\n",
    "        'Plaza Espa√±a 7, Barcelona', 'Calle Real 89, Sevilla',\n",
    "        'Madrid', 'Valencia', 'Barcelona', 'Calle Nueva 12, Madrid',\n",
    "        'Sevilla', 'Avenida Central 34, Madrid', 'Valencia',\n",
    "        'Calle Luna 56, Barcelona', 'Madrid', 'Sevilla', 'Valencia'\n",
    "    ],\n",
    "    'metodo': [\n",
    "        'ahorcamiento', 'intoxicacion', 'arma de fuego', 'ahorcamiento', 'precipitacion',\n",
    "        'ahorcamiento', 'intoxicacion', None, 'arma de fuego', 'ahorcamiento',\n",
    "        'intoxicacion', 'ahorcamiento', 'precipitacion', 'intoxicacion', 'ahorcamiento'\n",
    "    ],\n",
    "    'municipio': [\n",
    "        'Madrid', 'Valencia', 'Barcelona', 'Sevilla', 'Madrid',\n",
    "        'Valencia', 'Barcelona', 'Madrid', 'Sevilla', 'Madrid',\n",
    "        'Valencia', 'Barcelona', 'Madrid', 'Sevilla', 'Valencia'\n",
    "    ],\n",
    "    'tipo_evento': [\n",
    "        'consumado', 'intento', 'consumado', 'intento', 'consumado',\n",
    "        'consumado', 'intento', 'intento', 'consumado', 'intento',\n",
    "        'consumado', 'intento', 'consumado', 'intento', 'consumado'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"Dataset creado: {len(df_with_pii)} registros\")\n",
    "print(f\"\\n‚ö†Ô∏è Columnas con PII:\")\n",
    "print(\"  - nombre_completo\")\n",
    "print(\"  - dni\")\n",
    "print(\"  - telefono\")\n",
    "print(\"  - direccion (algunas con direcci√≥n exacta)\")\n",
    "\n",
    "df_with_pii.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Ejecutar An√°lisis Completo\n",
    "\n",
    "Esto ejecuta los 6 analizadores en paralelo + anonimizaci√≥n autom√°tica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fase3_evaluator.integration.orchestrator:Iniciando an√°lisis paralelo de 'dataset_con_pii.csv' con 15 registros y 12 columnas\n",
      "INFO:fase3_evaluator.integration.orchestrator:Ejecutando analizadores en paralelo...\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì typology completado\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì geospatial completado\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì semantic completado\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì completeness completado\n",
      "/Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/cuidar_ia_fase3 4/notebooks/../fase3_evaluator/analyzers/anonymization.py:239: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  detailed_addresses = series[series.str.contains(detailed_pattern, na=False)]\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì anonymization completado\n",
      "INFO:fase3_evaluator.integration.orchestrator:‚úì ml_readiness completado\n",
      "WARNING:fase3_evaluator.integration.orchestrator:PII detectada en 5 columnas - anonimizando...\n",
      "INFO:fase3_evaluator.integration.orchestrator:Anonimizaci√≥n completada y validada\n",
      "INFO:fase3_evaluator.integration.orchestrator:Consolidando resultados...\n",
      "WARNING:fase3_evaluator.integration.orchestrator:Advertencia en validaci√≥n Pydantic: 1 validation error for ConsolidatedAnalysis\n",
      "ml.model_suggestions.0.models\n",
      "  Input should be a valid string [type=string_type, input_value=['Logistic Regression', '...ndom Forest', 'XGBoost'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "INFO:fase3_evaluator.integration.orchestrator:An√°lisis completado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ejecutando an√°lisis paralelo...\n",
      "\n",
      "\n",
      "‚úÖ An√°lisis completado\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar an√°lisis completo\n",
    "print(\"üöÄ Ejecutando an√°lisis paralelo...\\n\")\n",
    "\n",
    "consolidated_json, df_anonymized, anonymization_report = run_parallel_analysis(\n",
    "    df_with_pii,\n",
    "    filename=\"dataset_con_pii.csv\",\n",
    "    auto_anonymize=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Verificar Anonimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REPORTE DE ANONIMIZACI√ìN\n",
      "============================================================\n",
      "Columnas originales: 12\n",
      "Columnas anonimizadas: 12\n",
      "Columnas eliminadas: 0\n",
      "Transformaciones aplicadas: 5\n",
      "\n",
      "üìã Detalles de transformaciones:\n",
      "  - id_registro: removed\n",
      "  - nombre_completo: masked\n",
      "  - dni: removed\n",
      "  - telefono: masked_partial\n",
      "  - direccion: aggregated_to_municipality\n",
      "\n",
      "‚úÖ Validaci√≥n:\n",
      "  - Seguro: S√≠\n",
      "  - Riesgo residual PII: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Mostrar reporte de anonimizaci√≥n\n",
    "if anonymization_report:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REPORTE DE ANONIMIZACI√ìN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Columnas originales: {anonymization_report['original_columns']}\")\n",
    "    print(f\"Columnas anonimizadas: {anonymization_report['anonymized_columns']}\")\n",
    "    print(f\"Columnas eliminadas: {anonymization_report['columns_removed']}\")\n",
    "    print(f\"Transformaciones aplicadas: {anonymization_report['transformations_applied']}\")\n",
    "    \n",
    "    print(\"\\nüìã Detalles de transformaciones:\")\n",
    "    for col, transform in anonymization_report['transformation_details'].items():\n",
    "        print(f\"  - {col}: {transform}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Validaci√≥n:\")\n",
    "    validation = anonymization_report['validation']\n",
    "    print(f\"  - Seguro: {'S√≠' if validation['is_safe'] else 'No'}\")\n",
    "    print(f\"  - Riesgo residual PII: {validation['residual_pii_risk']:.1f}\")\n",
    "    if validation['warnings']:\n",
    "        print(f\"  - Advertencias: {len(validation['warnings'])}\")\n",
    "        for warning in validation['warnings']:\n",
    "            print(f\"    ‚ö†Ô∏è {warning}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No se detect√≥ PII - no se requiri√≥ anonimizaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Comparar Datos Originales vs Anonimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARACI√ìN: ORIGINAL vs ANONIMIZADO\n",
      "\n",
      "\n",
      "üìä Columna: id_registro\n",
      "----------------------------------------\n",
      "   Original  Anonimizado\n",
      "0         1          NaN\n",
      "1         2          NaN\n",
      "2         3          NaN\n",
      "3         4          NaN\n",
      "4         5          NaN\n",
      "\n",
      "üìä Columna: nombre_completo\n",
      "----------------------------------------\n",
      "                 Original Anonimizado\n",
      "0       Juan Garc√≠a L√≥pez   PERSONA_1\n",
      "1   Mar√≠a Rodr√≠guez P√©rez   PERSONA_2\n",
      "2  Pedro Mart√≠nez S√°nchez   PERSONA_3\n",
      "3     Ana L√≥pez Fern√°ndez   PERSONA_4\n",
      "4   Carlos S√°nchez Garc√≠a   PERSONA_5\n",
      "\n",
      "üìä Columna: dni\n",
      "----------------------------------------\n",
      "    Original  Anonimizado\n",
      "0  12345678A          NaN\n",
      "1  23456789B          NaN\n",
      "2  34567890C          NaN\n",
      "3  45678901D          NaN\n",
      "4  56789012E          NaN\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n lado a lado\n",
    "print(\"COMPARACI√ìN: ORIGINAL vs ANONIMIZADO\\n\")\n",
    "\n",
    "# Seleccionar columnas que fueron anonimizadas\n",
    "if anonymization_report:\n",
    "    pii_cols = list(anonymization_report['transformation_details'].keys())\n",
    "    \n",
    "    for col in pii_cols[:3]:  # Primeras 3 columnas\n",
    "        if col in df_with_pii.columns and col in df_anonymized.columns:\n",
    "            print(f\"\\nüìä Columna: {col}\")\n",
    "            print(\"-\" * 40)\n",
    "            comparison = pd.DataFrame({\n",
    "                'Original': df_with_pii[col].head(5),\n",
    "                'Anonimizado': df_anonymized[col].head(5)\n",
    "            })\n",
    "            print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Resumen Ejecutivo del An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN EJECUTIVO\n",
      "============================================================\n",
      "\n",
      "üìä Dataset: 15 registros, 12 columnas\n",
      "\n",
      "üéØ Scores de Calidad:\n",
      "  ‚úÖ Completitud: 98.3/100\n",
      "  ‚úÖ Tipologia: 96.7/100\n",
      "  ‚úÖ Semantica: 100.0/100\n",
      "  ‚ö†Ô∏è Geoespacial: 50.0/100\n",
      "  ‚ùå Ml_viabilidad: 20.0/100\n",
      "\n",
      "üìà Score General: 73.0/100\n",
      "\n",
      "‚ö†Ô∏è Issues Cr√≠ticos:\n",
      "  - PII detectada: S√≠\n",
      "    Nivel de riesgo: critico\n",
      "  - Completitud cr√≠tica: No\n",
      "  - Riesgos de leakage: 0\n",
      "\n",
      "üöÄ Capacidades:\n",
      "  - Geocodificable: S√≠\n",
      "  - ML viable: No\n",
      "  - Clustering factible: No\n"
     ]
    }
   ],
   "source": [
    "# Generar resumen ejecutivo\n",
    "summary = get_analysis_summary(consolidated_json)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN EJECUTIVO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset: {summary['dataset']['rows']} registros, {summary['dataset']['columns']} columnas\")\n",
    "\n",
    "print(f\"\\nüéØ Scores de Calidad:\")\n",
    "for metric, score in summary['scores'].items():\n",
    "    emoji = \"‚úÖ\" if score >= 70 else \"‚ö†Ô∏è\" if score >= 50 else \"‚ùå\"\n",
    "    print(f\"  {emoji} {metric.capitalize()}: {score:.1f}/100\")\n",
    "\n",
    "print(f\"\\nüìà Score General: {summary['overall_score']:.1f}/100\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Issues Cr√≠ticos:\")\n",
    "print(f\"  - PII detectada: {'S√≠' if summary['critical_issues']['pii_detected'] else 'No'}\")\n",
    "if summary['critical_issues']['pii_detected']:\n",
    "    print(f\"    Nivel de riesgo: {summary['critical_issues']['pii_risk_level']}\")\n",
    "print(f\"  - Completitud cr√≠tica: {'S√≠' if summary['critical_issues']['completitud_critica'] else 'No'}\")\n",
    "print(f\"  - Riesgos de leakage: {summary['critical_issues']['leakage_risks']}\")\n",
    "\n",
    "print(f\"\\nüöÄ Capacidades:\")\n",
    "print(f\"  - Geocodificable: {'S√≠' if summary['capabilities']['geocodable'] else 'No'}\")\n",
    "print(f\"  - ML viable: {'S√≠' if summary['capabilities']['ml_viable'] else 'No'}\")\n",
    "print(f\"  - Clustering factible: {'S√≠' if summary['capabilities']['clustering_feasible'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Generar Diagn√≥stico con LLM\n",
    "\n",
    "‚ö†Ô∏è **NOTA**: Esto requiere que tengas configurada tu `OPENAI_API_KEY` en el archivo `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fase3_evaluator.agent.interpreter:Generando diagn√≥stico con OpenAI...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Generando diagn√≥stico con OpenAI...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:fase3_evaluator.agent.interpreter:Diagn√≥stico generado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIAGN√ìSTICO GENERADO POR IA\n",
      "============================================================\n",
      "\n",
      "Modelo usado: gpt-4o\n",
      "Tokens utilizados: 7264\n",
      "\n",
      "============================================================\n",
      "\n",
      "## 1. DIAGN√ìSTICO GENERAL\n",
      "El dataset analizado contiene 15 registros y 12 columnas, con datos que incluyen informaci√≥n personal y eventos relacionados con el suicidio. La calidad general del dataset es excelente en t√©rminos de completitud, con solo un 1.67% de datos faltantes. Sin embargo, se identificaron problemas cr√≠ticos relacionados con la presencia de informaci√≥n personal identificable (PII), lo que representa un riesgo √©tico y legal significativo. Adem√°s, hay inconsistencias en la tipolog√≠a de datos, especialmente en la columna \"sexo\", que afecta la precisi√≥n de los an√°lisis cuantitativos.\n",
      "\n",
      "## 2. AN√ÅLISIS QUE S√ç SE PUEDEN REALIZAR\n",
      "‚úÖ **An√°lisis Descriptivo de Distribuciones**\n",
      "üìä Aporta informaci√≥n sobre la distribuci√≥n de variables clave como edad, sexo y m√©todo de suicidio.\n",
      "üéØ Apoya decisiones de prevenci√≥n al identificar grupos demogr√°ficos de mayor riesgo.\n",
      "\n",
      "‚úÖ **An√°lisis de Correlaciones B√°sicas**\n",
      "üìä Permite detectar asociaciones entre variables categ√≥ricas y num√©ricas.\n",
      "üéØ Informa sobre posibles factores de riesgo asociados, aunque no establece causalidad.\n",
      "\n",
      "## 3. AN√ÅLISIS QUE NO SE PUEDEN REALIZAR (Y POR QU√â)\n",
      "‚ùå **Modelos de Machine Learning Predictivos**\n",
      "   Raz√≥n: Insuficientes muestras (15 < 100 requeridas) y caracter√≠sticas √∫tiles (4 < 5).\n",
      "   Para desbloquearlo: Ampliar el dataset y mejorar la calidad de las caracter√≠sticas.\n",
      "\n",
      "‚ùå **An√°lisis Geoespacial Detallado**\n",
      "   Raz√≥n: Cobertura geocodificable parcial (46.67%) y falta de datos de coordenadas.\n",
      "   Para desbloquearlo: Mejorar la precisi√≥n de las direcciones y aumentar el n√∫mero de registros.\n",
      "\n",
      "## 4. HALLAZGOS DESCRIPTIVOS CLAVE\n",
      "- **Distribuci√≥n por Edad**: La media de edad es de aproximadamente 39 a√±os, con un rango de 25 a 60 a√±os.\n",
      "- **Distribuci√≥n por Sexo**: 53.3% de los casos son hombres y 46.7% son mujeres.\n",
      "- **M√©todo de Suicidio**: El ahorcamiento es el m√©todo m√°s com√∫n (40%), seguido de la intoxicaci√≥n (26.7%).\n",
      "- **Localidad**: La mayor√≠a de los casos se concentran en Madrid, Valencia y Barcelona.\n",
      "\n",
      "## 5. CORRELACIONES Y PATRONES IDENTIFICADOS\n",
      "No se identificaron correlaciones significativas debido a la falta de datos suficientes y la calidad inconsistente de algunas variables. Sin embargo, se sugiere explorar la relaci√≥n entre edad y m√©todo de suicidio en futuros an√°lisis con datos m√°s completos.\n",
      "\n",
      "## 6. RIESGOS √âTICOS Y DE PRIVACIDAD\n",
      "‚ö†Ô∏è Se detect√≥ PII en 5 columnas, incluyendo nombres completos, DNI y n√∫meros de tel√©fono. Esto implica un riesgo cr√≠tico de re-identificaci√≥n y violaci√≥n de regulaciones como el RGPD. Aunque el dataset fue auto-anonimizado, es crucial eliminar o anonimizar completamente estas columnas antes de cualquier uso adicional.\n",
      "\n",
      "## 7. RECOMENDACIONES PRIORIZADAS\n",
      "1. **[Prioridad CR√çTICA] Eliminar PII**: Eliminar las columnas con PII o aplicar hash irreversible. Impacto: Alto, protege contra riesgos legales. Dificultad: Media.\n",
      "2. **[Prioridad ALTA] Estandarizar Datos de Sexo**: Corregir inconsistencias en la columna \"sexo\". Impacto: Alto, mejora la precisi√≥n anal√≠tica. Dificultad: F√°cil.\n",
      "3. **[Prioridad MEDIA] Ampliar Dataset**: Recopilar m√°s datos para permitir an√°lisis m√°s robustos. Impacto: Medio, habilita an√°lisis m√°s complejos. Dificultad: Dif√≠cil.\n",
      "4. **[Prioridad MEDIA] Mejorar Geocodificaci√≥n**: Refinar direcciones para mejorar an√°lisis geoespaciales. Impacto: Medio, mejora la capacidad de an√°lisis espacial. Dificultad: Media.\n",
      "5. **[Prioridad BAJA] Revisar y Corregir Inconsistencias**: Asegurar la consistencia de todos los datos categ√≥ricos. Impacto: Bajo, pero mejora la calidad general. Dificultad: F√°cil.\n",
      "\n",
      "En conclusi√≥n, aunque el dataset presenta desaf√≠os significativos, especialmente en t√©rminos de privacidad y cantidad de datos, su an√°lisis puede ofrecer informaci√≥n valiosa para la prevenci√≥n del suicidio. Con las acciones correctivas adecuadas, se puede mejorar su utilidad y seguridad.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la API key est√° configurada\n",
    "if not settings.OPENAI_API_KEY:\n",
    "    print(\"‚ùå ERROR: OPENAI_API_KEY no est√° configurada\")\n",
    "    print(\"\\nPara configurarla:\")\n",
    "    print(\"1. Copia .env.example a .env\")\n",
    "    print(\"2. Edita .env y pega tu API key\")\n",
    "    print(\"3. Reinicia el kernel del notebook\")\n",
    "else:\n",
    "    print(\"ü§ñ Generando diagn√≥stico con OpenAI...\\n\")\n",
    "    \n",
    "    try:\n",
    "        diagnosis_result = generate_diagnosis(\n",
    "            consolidated_json,\n",
    "            df_anonymized,\n",
    "            include_sample=True\n",
    "        )\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"DIAGN√ìSTICO GENERADO POR IA\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nModelo usado: {diagnosis_result['model_used']}\")\n",
    "        print(f\"Tokens utilizados: {diagnosis_result['tokens_used']}\")\n",
    "        print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "        print(diagnosis_result['diagnosis'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al generar diagn√≥stico: {str(e)}\")\n",
    "        print(\"\\nVerifica:\")\n",
    "        print(\"1. Que tu API key sea v√°lida\")\n",
    "        print(\"2. Que tengas cr√©ditos disponibles en OpenAI\")\n",
    "        print(\"3. Que tengas conexi√≥n a internet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion de conversion cargada\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convierte tipos NumPy a tipos nativos Python para JSON serialization\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    elif isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "print(\"Funcion de conversion cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON guardado en: ../data/outputs/analisis_completo.json\n",
      "CSV guardado en: ../data/outputs/datos_anonimizados_flujo_completo.csv\n",
      "Diagnostico guardado en: ../data/outputs/diagnostico_flujo_completo.md\n",
      "\n",
      "Todos los archivos en: /Users/reinerfuentesferrada/ONLINE_DS_THEBRIDGE_Rei/Proyecto ML/cuidar-ia/cuidar_ia_fase3 4/notebooks/../data/outputs\n"
     ]
    }
   ],
   "source": [
    "# Paso 7: Guardar Resultados\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = Path('../data/outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# JSON completo - CONVERTIR ANTES DE GUARDAR\n",
    "json_path = output_dir / 'analisis_completo.json'\n",
    "consolidated_json_clean = convert_numpy_types(consolidated_json)\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(consolidated_json_clean, f, indent=2, ensure_ascii=False)\n",
    "print(f\"JSON guardado en: {json_path}\")\n",
    "\n",
    "# Datos anonimizados\n",
    "csv_path = output_dir / 'datos_anonimizados_flujo_completo.csv'\n",
    "df_anonymized.to_csv(csv_path, index=False)\n",
    "print(f\"CSV guardado en: {csv_path}\")\n",
    "\n",
    "# Diagn√≥stico (si existe)\n",
    "if 'diagnosis_result' in locals() and diagnosis_result:\n",
    "    md_path = output_dir / 'diagnostico_flujo_completo.md'\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# Diagnostico Automatico\\n\")\n",
    "        f.write(f\"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(diagnosis_result['diagnosis'])\n",
    "    print(f\"Diagnostico guardado en: {md_path}\")\n",
    "\n",
    "print(f\"\\nTodos los archivos en: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬°Flujo Completado!\n",
    "\n",
    "Has ejecutado exitosamente:\n",
    "- ‚úÖ An√°lisis paralelo de 6 dimensiones\n",
    "- ‚úÖ Detecci√≥n autom√°tica de PII\n",
    "- ‚úÖ Anonimizaci√≥n autom√°tica\n",
    "- ‚úÖ Generaci√≥n de diagn√≥stico con IA\n",
    "- ‚úÖ Exportaci√≥n de resultados\n",
    "\n",
    "**Pr√≥ximos pasos**:\n",
    "1. Prueba con tus propios datos reales\n",
    "2. Ajusta los umbrales en `config/settings.py`\n",
    "3. Personaliza los prompts del agente\n",
    "4. Integra con tu flujo de Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cuidar (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
